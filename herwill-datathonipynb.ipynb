{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":87202,"databundleVersionId":9907921,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-25T15:19:21.376602Z","iopub.execute_input":"2024-10-25T15:19:21.377452Z","iopub.status.idle":"2024-10-25T15:19:21.385320Z","shell.execute_reply.started":"2024-10-25T15:19:21.377391Z","shell.execute_reply":"2024-10-25T15:19:21.384355Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/her-will-ai-for-equality-datathon-2024/sample_submission.csv\n/kaggle/input/her-will-ai-for-equality-datathon-2024/train.csv\n/kaggle/input/her-will-ai-for-equality-datathon-2024/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/her-will-ai-for-equality-datathon-2024/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/her-will-ai-for-equality-datathon-2024/test.csv\")\ndf_sub = pd.read_csv(\"/kaggle/input/her-will-ai-for-equality-datathon-2024/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:19:25.027882Z","iopub.execute_input":"2024-10-25T15:19:25.028313Z","iopub.status.idle":"2024-10-25T15:19:25.073903Z","shell.execute_reply.started":"2024-10-25T15:19:25.028268Z","shell.execute_reply":"2024-10-25T15:19:25.072907Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:19:35.031105Z","iopub.execute_input":"2024-10-25T15:19:35.031694Z","iopub.status.idle":"2024-10-25T15:19:35.052458Z","shell.execute_reply.started":"2024-10-25T15:19:35.031634Z","shell.execute_reply":"2024-10-25T15:19:35.051186Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   id                                            passage  y\n0   0  Women are always the ones struggling in math c...  1\n1   1  Men in education often just boss around and ne...  0\n2   2  Non-binary students are just confused about th...  2\n3   3  Science classrooms are designed to be neutral ...  3\n4   4  Male teachers often believe they are superior ...  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>passage</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Women are always the ones struggling in math c...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Men in education often just boss around and ne...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Non-binary students are just confused about th...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Science classrooms are designed to be neutral ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Male teachers often believe they are superior ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import BertTokenizer\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nimport tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:23:36.809995Z","iopub.execute_input":"2024-10-25T15:23:36.810480Z","iopub.status.idle":"2024-10-25T15:23:36.860705Z","shell.execute_reply.started":"2024-10-25T15:23:36.810409Z","shell.execute_reply":"2024-10-25T15:23:36.858950Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtokenizer\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tokenizer'"],"ename":"ModuleNotFoundError","evalue":"No module named 'tokenizer'","output_type":"error"}]},{"cell_type":"code","source":"# Define the maximum length for padding\nmax_len = 160\n\n# Define a function for tokenizing the text\ndef tokenize_data(texts, max_len):\n    # Tokenize and prepare inputs for BERT\n    inputs = tokenizer(\n        texts.tolist(),\n        max_length=max_len,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"tf\"\n    )\n    return inputs[\"input_ids\"], inputs[\"attention_mask\"], inputs[\"token_type_ids\"]\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:23:21.577364Z","iopub.execute_input":"2024-10-25T15:23:21.577796Z","iopub.status.idle":"2024-10-25T15:23:21.584485Z","shell.execute_reply.started":"2024-10-25T15:23:21.577756Z","shell.execute_reply":"2024-10-25T15:23:21.583316Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:21:53.068578Z","iopub.execute_input":"2024-10-25T15:21:53.069034Z","iopub.status.idle":"2024-10-25T15:21:53.076813Z","shell.execute_reply.started":"2024-10-25T15:21:53.068990Z","shell.execute_reply":"2024-10-25T15:21:53.075866Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Apply tokenization on the 'passage' column\ninput_ids, attention_masks, token_type_ids = tokenize_data(df_train[\"passage\"], max_len)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:23:23.724015Z","iopub.execute_input":"2024-10-25T15:23:23.724903Z","iopub.status.idle":"2024-10-25T15:23:23.857170Z","shell.execute_reply.started":"2024-10-25T15:23:23.724847Z","shell.execute_reply":"2024-10-25T15:23:23.855549Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply tokenization on the 'passage' column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m input_ids, attention_masks, token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[14], line 7\u001b[0m, in \u001b[0;36mtokenize_data\u001b[0;34m(texts, max_len)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_data\u001b[39m(texts, max_len):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Tokenize and prepare inputs for BERT\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mTokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m], inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/text.py:105\u001b[0m, in \u001b[0;36mTokenizer.__init__\u001b[0;34m(self, num_words, filters, lower, split, char_level, oov_token, analyzer, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m document_count \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(kwargs))\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_counts \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mOrderedDict()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_docs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mint\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: Unrecognized keyword arguments: {'max_length': 160, 'padding': 'max_length', 'truncation': True, 'return_tensors': 'tf'}"],"ename":"TypeError","evalue":"Unrecognized keyword arguments: {'max_length': 160, 'padding': 'max_length', 'truncation': True, 'return_tensors': 'tf'}","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T14:39:40.774100Z","iopub.execute_input":"2024-10-25T14:39:40.774561Z","iopub.status.idle":"2024-10-25T14:39:40.795912Z","shell.execute_reply.started":"2024-10-25T14:39:40.774515Z","shell.execute_reply":"2024-10-25T14:39:40.794350Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id                                            passage  y\n0   0  Women are always the ones struggling in math c...  1\n1   1  Men in education often just boss around and ne...  0\n2   2  Non-binary students are just confused about th...  2\n3   3  Science classrooms are designed to be neutral ...  3\n4   4  Male teachers often believe they are superior ...  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>passage</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Women are always the ones struggling in math c...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Men in education often just boss around and ne...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Non-binary students are just confused about th...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Science classrooms are designed to be neutral ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Male teachers often believe they are superior ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_sub.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T14:39:56.978196Z","iopub.execute_input":"2024-10-25T14:39:56.978732Z","iopub.status.idle":"2024-10-25T14:39:56.996201Z","shell.execute_reply.started":"2024-10-25T14:39:56.978652Z","shell.execute_reply":"2024-10-25T14:39:56.994591Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     id  y_pred    parameters\n0  7000       0  1.000000e+10\n1  7001       0  1.000000e+10\n2  7002       0  1.000000e+10\n3  7003       0  1.000000e+10\n4  7004       0  1.000000e+10","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>y_pred</th>\n      <th>parameters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7000</td>\n      <td>0</td>\n      <td>1.000000e+10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7001</td>\n      <td>0</td>\n      <td>1.000000e+10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7002</td>\n      <td>0</td>\n      <td>1.000000e+10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7003</td>\n      <td>0</td>\n      <td>1.000000e+10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7004</td>\n      <td>0</td>\n      <td>1.000000e+10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install keras-core --upgrade\n!pip install -q keras-nlp --upgrade","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:15:30.794390Z","iopub.execute_input":"2024-10-25T15:15:30.795245Z","iopub.status.idle":"2024-10-25T15:16:08.312862Z","shell.execute_reply.started":"2024-10-25T15:15:30.795173Z","shell.execute_reply":"2024-10-25T15:16:08.311097Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-core in /opt/conda/lib/python3.10/site-packages (0.1.7)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-core) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-core) (3.11.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.1.8)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core) (0.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py","metadata":{"execution":{"iopub.status.busy":"2024-10-25T14:43:13.281772Z","iopub.execute_input":"2024-10-25T14:43:13.282565Z","iopub.status.idle":"2024-10-25T14:43:14.793069Z","shell.execute_reply.started":"2024-10-25T14:43:13.282515Z","shell.execute_reply":"2024-10-25T14:43:14.791270Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\n#import tokenization\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2024-10-25T14:43:47.428791Z","iopub.execute_input":"2024-10-25T14:43:47.429412Z","iopub.status.idle":"2024-10-25T14:43:47.449203Z","shell.execute_reply.started":"2024-10-25T14:43:47.429354Z","shell.execute_reply":"2024-10-25T14:43:47.447788Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n        tokens += [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T14:44:48.854541Z","iopub.execute_input":"2024-10-25T14:44:48.855138Z","iopub.status.idle":"2024-10-25T14:44:48.866564Z","shell.execute_reply.started":"2024-10-25T14:44:48.855081Z","shell.execute_reply":"2024-10-25T14:44:48.865260Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def build_model(bert_layer, max_len=160, num_classes=4):\n    # Define input layers for tokenized inputs\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n\n    # BERT layer: use bert_layer and pass inputs as a single list\n    bert_inputs = [input_word_ids, input_mask, segment_ids]\n    bert_outputs = bert_layer(bert_inputs)\n\n    # Using 'sequence_output' as a fallback if 'pooled_output' causes issues\n    pooled_output = bert_outputs[\"pooled_output\"] if \"pooled_output\" in bert_outputs else bert_outputs[0][:, 0]\n\n    # Classification layer (softmax for multi-class)\n    output = Dense(num_classes, activation=\"softmax\")(pooled_output)\n\n    # Build and compile the model\n    model = Model(inputs=bert_inputs, outputs=output)\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n                  loss=\"categorical_crossentropy\",\n                  metrics=[\"accuracy\"])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:12:25.009948Z","iopub.execute_input":"2024-10-25T15:12:25.010492Z","iopub.status.idle":"2024-10-25T15:12:25.024584Z","shell.execute_reply.started":"2024-10-25T15:12:25.010438Z","shell.execute_reply":"2024-10-25T15:12:25.022290Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\nbert_layer = hub.KerasLayer(module_url, trainable=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T14:45:12.312158Z","iopub.execute_input":"2024-10-25T14:45:12.312657Z","iopub.status.idle":"2024-10-25T14:45:51.526041Z","shell.execute_reply.started":"2024-10-25T14:45:12.312611Z","shell.execute_reply":"2024-10-25T14:45:51.524610Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-10-25T14:47:45.470887Z","iopub.execute_input":"2024-10-25T14:47:45.471373Z","iopub.status.idle":"2024-10-25T14:47:45.479036Z","shell.execute_reply.started":"2024-10-25T14:47:45.471325Z","shell.execute_reply":"2024-10-25T14:47:45.477531Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n\nfrom transformers import BertTokenizer, TFBertModel\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nbert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:01:02.706068Z","iopub.execute_input":"2024-10-25T15:01:02.706648Z","iopub.status.idle":"2024-10-25T15:01:11.392258Z","shell.execute_reply.started":"2024-10-25T15:01:02.706602Z","shell.execute_reply":"2024-10-25T15:01:11.390715Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c822a54834746ea8ba3a6d84ad7e5b2"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_input = bert_encode(df_train.passage.values, tokenizer, max_len=160)\ntest_input = bert_encode(df_test.passage.values, tokenizer, max_len=160)\ntrain_labels = df_train['y'].values","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:01:19.004220Z","iopub.execute_input":"2024-10-25T15:01:19.004997Z","iopub.status.idle":"2024-10-25T15:01:31.703867Z","shell.execute_reply.started":"2024-10-25T15:01:19.004950Z","shell.execute_reply":"2024-10-25T15:01:31.702479Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"print(hub.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:11:53.395872Z","iopub.execute_input":"2024-10-25T15:11:53.396342Z","iopub.status.idle":"2024-10-25T15:11:53.403818Z","shell.execute_reply.started":"2024-10-25T15:11:53.396295Z","shell.execute_reply":"2024-10-25T15:11:53.402126Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"0.16.1\n","output_type":"stream"}]},{"cell_type":"code","source":"bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\nmodel = build_model(bert_layer, max_len=160, num_classes=4)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T15:16:15.894441Z","iopub.execute_input":"2024-10-25T15:16:15.894944Z","iopub.status.idle":"2024-10-25T15:16:23.056728Z","shell.execute_reply.started":"2024-10-25T15:16:15.894896Z","shell.execute_reply":"2024-10-25T15:16:23.054455Z"},"trusted":true},"execution_count":40,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bert_layer \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mKerasLayer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\u001b[39m\u001b[38;5;124m\"\u001b[39m, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n","Cell \u001b[0;32mIn[37], line 9\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(bert_layer, max_len, num_classes)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# BERT layer: use bert_layer and pass inputs as a single list\u001b[39;00m\n\u001b[1;32m      8\u001b[0m bert_inputs \u001b[38;5;241m=\u001b[39m [input_word_ids, input_mask, segment_ids]\n\u001b[0;32m----> 9\u001b[0m bert_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbert_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Using 'sequence_output' as a fallback if 'pooled_output' causes issues\u001b[39;00m\n\u001b[1;32m     12\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m bert_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpooled_output\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpooled_output\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m bert_outputs \u001b[38;5;28;01melse\u001b[39;00m bert_outputs[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py:250\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Behave like BatchNormalization. (Dropout is different, b/181839368.)\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43msmart_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# Unwrap dicts returned by signatures.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_key:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py:252\u001b[0m, in \u001b[0;36mKerasLayer.call.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Behave like BatchNormalization. (Dropout is different, b/181839368.)\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    250\u001b[0m   result \u001b[38;5;241m=\u001b[39m smart_cond\u001b[38;5;241m.\u001b[39msmart_cond(training,\n\u001b[1;32m    251\u001b[0m                                  \u001b[38;5;28;01mlambda\u001b[39;00m: f(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m--> 252\u001b[0m                                  \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# Unwrap dicts returned by signatures.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_key:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:583\u001b[0m, in \u001b[0;36mcanonicalize_to_monomorphic\u001b[0;34m(args, kwargs, default_values, capture_types, polymorphic_type)\u001b[0m\n\u001b[1;32m    577\u001b[0m       parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    578\u001b[0m           _make_validated_mono_param(kwarg_name, arg[kwarg_name],\n\u001b[1;32m    579\u001b[0m                                      Parameter\u001b[38;5;241m.\u001b[39mKEYWORD_ONLY, type_context,\n\u001b[1;32m    580\u001b[0m                                      poly_parameter\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[1;32m    581\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 583\u001b[0m         \u001b[43m_make_validated_mono_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly_parameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtype_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mpoly_parameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FunctionType(parameters, capture_types), type_context\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:522\u001b[0m, in \u001b[0;36m_make_validated_mono_param\u001b[0;34m(name, value, kind, type_context, poly_type)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_validated_mono_param\u001b[39m(\n\u001b[1;32m    519\u001b[0m     name, value, kind, type_context, poly_type\n\u001b[1;32m    520\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Parameter:\n\u001b[1;32m    521\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m   mono_type \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m poly_type \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mono_type\u001b[38;5;241m.\u001b[39mis_subtype_of(poly_type):\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was expected to be of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpoly_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmono_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:162\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m from_value(value\u001b[38;5;241m.\u001b[39m__wrapped__, context)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 162\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mList\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfrom_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    165\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mis_namedtuple(value):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:162\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m from_value(value\u001b[38;5;241m.\u001b[39m__wrapped__, context)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 162\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mList(\u001b[38;5;241m*\u001b[39m(\u001b[43mfrom_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m value))\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    165\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mis_namedtuple(value):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:185\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mAttrs\u001b[38;5;241m.\u001b[39mfrom_type_and_attributes(\n\u001b[1;32m    179\u001b[0m       \u001b[38;5;28mtype\u001b[39m(value),\n\u001b[1;32m    180\u001b[0m       \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    181\u001b[0m           from_value(\u001b[38;5;28mgetattr\u001b[39m(value, a\u001b[38;5;241m.\u001b[39mname), context)\n\u001b[1;32m    182\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__attrs_attrs__))\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mis_np_ndarray(value):\n\u001b[0;32m--> 185\u001b[0m   ndarray \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mTENSOR(ndarray\u001b[38;5;241m.\u001b[39mshape, ndarray\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, custom_nest_protocol\u001b[38;5;241m.\u001b[39mCustomNestProtocol):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/common/keras_tensor.py:61\u001b[0m, in \u001b[0;36mKerasTensor.__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is symbolic: it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms a placeholder for a shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man a dtype. It doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have any actual numerical value. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot convert it to a NumPy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'keras_layer_4' (type KerasLayer).\n\nA KerasTensor is symbolic: it's a placeholder for a shape an a dtype. It doesn't have any actual numerical value. You cannot convert it to a NumPy array.\n\nCall arguments received by layer 'keras_layer_4' (type KerasLayer):\n  • inputs=['<KerasTensor shape=(None, 160), dtype=int32, sparse=None, name=input_word_ids>', '<KerasTensor shape=(None, 160), dtype=int32, sparse=None, name=input_mask>', '<KerasTensor shape=(None, 160), dtype=int32, sparse=None, name=segment_ids>']\n  • training=None"],"ename":"ValueError","evalue":"Exception encountered when calling layer 'keras_layer_4' (type KerasLayer).\n\nA KerasTensor is symbolic: it's a placeholder for a shape an a dtype. It doesn't have any actual numerical value. You cannot convert it to a NumPy array.\n\nCall arguments received by layer 'keras_layer_4' (type KerasLayer):\n  • inputs=['<KerasTensor shape=(None, 160), dtype=int32, sparse=None, name=input_word_ids>', '<KerasTensor shape=(None, 160), dtype=int32, sparse=None, name=input_mask>', '<KerasTensor shape=(None, 160), dtype=int32, sparse=None, name=segment_ids>']\n  • training=None","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}